{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsX9HcswkMhh"
      },
      "source": [
        "# Workshop 2.1 : web parsing with str functions\n",
        "We will crawl data from https://www.chula.ac.th/en/academics/faculties-and-schools/\n",
        "\n",
        "which is mirrored here https://comprogchula.github.io/\n",
        "\n",
        "<img src =\"https://github.com/Mixelon-tera/Workshop2_Datascraping_Resource/raw/master/source/intro_scraping.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3pkX1wP3kMhi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/catsunoki/2110101-com-prog/webscrape\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "import urllib.request as urq\n",
        "import os\n",
        "\n",
        "dir_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
        "print(dir_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F59BwNdMieQw"
      },
      "source": [
        "### Tip! \n",
        " \n",
        "#### สำหรับเรื่อง string ในภาษา python ต้องระวังเรื่อง escape character เรามักจะใช้เครื่องหมาย \\ นำหน้า escape character ดังนี้\n",
        "\n",
        "<img src=\"https://i2.wp.com/www.techpaste.com/wp-content/uploads/2014/06/Escape_Characters_Python.jpg?fit=441%2C425&ssl=1\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a5vdLTmkMhl"
      },
      "source": [
        "# TO DO 1 : Crawl \"Faculty Name\" [only 19 faculties] (1%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGZp9qD8kMhm"
      },
      "source": [
        "Print all Faculty name in Chulalongkorn University\n",
        "and print Number of Faculties like below image\n",
        "\n",
        "<img src=\"https://github.com/Mixelon-tera/Workshop2_Datascraping_Resource/raw/master/source/fac_name.png\" width=300>\n",
        "\n",
        "<img src=\"https://github.com/Mixelon-tera/Workshop2_Datascraping_Resource/raw/master/source/number_faculty.png\" width=300>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tF2I-cQFkMhn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Faculty of Allied Health Sciences\n",
            "Faculty of Architecture\n",
            "Faculty of Arts\n",
            "Faculty of Commerce and Accountancy\n",
            "Faculty of Communication Arts\n",
            "Faculty of Dentistry\n",
            "Faculty of Economics\n",
            "Faculty of Education\n",
            "Faculty of Engineering\n",
            "Faculty of Fine and Applied Arts\n",
            "Faculty of Law\n",
            "Faculty of Medicine\n",
            "Faculty of Nursing\n",
            "Faculty of Pharmaceutical Sciences\n",
            "Faculty of Political Science\n",
            "Faculty of Psychology\n",
            "Faculty of Science\n",
            "Faculty of Sports Science\n",
            "Faculty of Veterinary Science\n",
            "Number of Faculties :  19\n"
          ]
        }
      ],
      "source": [
        "### บางเว็บไซต์เราไม่สามารถใช้ urlopen ได้ตรงๆ เนื่องจากเว็บมีการป้องกันไว้ วิธีการแก้เบื้องต้นคือการใส่ header เพื่อหลอกเว็บไซต์ว่าเรากำลังใช้เว็บในการ request ข้อมูลเพจ ###\n",
        "### แต่ในการบ้านวันนี้เราสามารถใส่ url ลงใน urlopen ได้ตรงๆเลย เพราะเว็บไม่ได้มีการป้องกันไว้ ###\n",
        "\n",
        "url = 'https://comprogchula.github.io/'\n",
        "html = str(urq.urlopen(url).read().decode('utf-8'))\n",
        "\n",
        "# ---- TO DO 1 : Code Here ----\n",
        "op,ed,a = [],[],[]\n",
        "for i in range(len(html)):\n",
        "    if(html[i:i+2] == \"<a\"):op+=[i]\n",
        "    if(html[i:i+2] == \"a>\"):ed+=[i+2]\n",
        "\n",
        "for i in range(len(op)):a+=[html[op[i]:ed[i]]]\n",
        "\n",
        "cnt=0\n",
        "for tag in a:\n",
        "    if(\"Faculty\" not in tag):continue\n",
        "    bracket,name=0,\"\"\n",
        "    cnt+=1\n",
        "    for i in tag:\n",
        "        if(i == '>' or i == '<'):bracket+=1\n",
        "        if(bracket==2 and i!='>'):name+=i\n",
        "    print(name)\n",
        "print(f\"Number of Faculties :  {cnt}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J3G2YYEkMhq"
      },
      "source": [
        "# TO DO 2 : Crawl \"Faculty and Schools Image\" [21 faculties and schools] (1%)\n",
        "\n",
        "Print image's url and save image into folder 'faculty_image'\n",
        "\n",
        "#### Hint : save images into -> dir_path+\"/faculty_image\"+faculty_name\n",
        "\n",
        "<img src=\"https://github.com/pjumruspun/ComProg2021-Workshop/blob/main/Workshop-02-Scraping/images.png?raw=true\" width=600>\n",
        "\n",
        "<img src=\"https://github.com/pjumruspun/ComProg2021-Workshop/blob/main/Workshop-02-Scraping/images_dir.png?raw=true\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z7XGFlJ972N3"
      },
      "outputs": [],
      "source": [
        "#สร้าง folder ชื่อ faculty_image\n",
        "\n",
        "!mkdir -p faculty_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6egHZ54tTMX2"
      },
      "source": [
        "### ขั้นตอนการอ่านและบันทึกไฟล์ภาพ\n",
        "\n",
        "1. อ่านภาพจากลิงค์\n",
        "* d = url.urlopen( [ลิงค์ของภาพ] )\n",
        "---\n",
        "2. สร้างไฟล์พร้อมระบุตำแหน่งที่จะเก็บไฟล์ภาพ \n",
        "* l = open( [ระบุตำแหน่งที่จะเก็บภาพ] )\n",
        "---\n",
        "\n",
        "3. บันทึกข้อมูลภาพไปยังตำแหน่งที่เก็บไฟล์ตามที่ระบุไว้ในข้อ (2.)\n",
        "* l.write(d.read())\n",
        "---\n",
        "\n",
        "4. ปิดไฟล์\n",
        "* l.close()\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2JSrIjIHkMhq"
      },
      "outputs": [],
      "source": [
        "# ---- TO DO 2 : Code Here ----\n",
        "\n",
        "op = []\n",
        "for i in range(len(html)):\n",
        "    if(html[i:i+9] == \"data-src=\"):op+=[i+10]\n",
        "\n",
        "for op in op:\n",
        "    ed=op+10\n",
        "    while(html[ed]!='\"'):ed+=1\n",
        "    uri = html[op:ed]\n",
        "    if(\"aculty\" not in uri):continue\n",
        "\n",
        "    d = urq.urlopen(uri)\n",
        "    filename = uri[uri.rfind('/')+1:]\n",
        "    path = f'./faculty_image/{filename}'\n",
        "    I = open(path, 'wb')\n",
        "    I.write(d.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu9Lq8EYm_4O"
      },
      "source": [
        "# TO DO 3 : Crawl \"Faculty Telephone Number\" [19 Faculties] (1%)\n",
        "\n",
        "Print Tel. of each faculty in Chulalongkorn University\n",
        "\n",
        "*** Only Faculty ***\n",
        "\n",
        "<img src=\"https://github.com/pjumruspun/ComProg2021-Workshop/blob/main/Workshop-02-Scraping/tel.png?raw=true\" width=450>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7CUSb9KvkMht"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "faculty-of-allied-health-sciences-chulalongkorn-university\n",
            "     66 (0) 2218 1065\n",
            "faculty-of-architecture-chulalongkorn-university\n",
            "     66 2218 4302\n",
            "faculty-of-arts-chulalongkorn-university\n",
            "     66 2218 4870\n",
            "faculty-of-commerce-and-accountancy-chulalongkorn-university\n",
            "     66 2218 5758\n",
            "faculty-of-communication-arts-chulalongkorn-university\n",
            "     66 2218 2163\n",
            "faculty-of-dentistry-chulalongkorn-university\n",
            "     66 2218 8635, +66 2218 8653, +66 2218 9016\n",
            "faculty-of-economics-chulalongkorn-university\n",
            "     66 2218 6259\n",
            "faculty-of-education-chulalongkorn-university\n",
            "     66 2218 2565 ext. 6760\n",
            "faculty-of-engineering-chulalongkorn-university\n",
            "     66 2218 6337\n",
            "faculty-of-fine-and-applied-arts-chulalongkorn-university\n",
            "     66 2218 4583\n",
            "faculty-of-law-chulalongkorn-university\n",
            "     66 2218 2017\n",
            "faculty-of-medicine-chulalongkorn-university\n",
            "     66 2256 4288, +66 2256 4000 ext. 3404\n",
            "faculty-of-nursing-chulalongkorn-university\n",
            "     66 2218 1131\n",
            "faculty-of-pharmaceutical-sciences-chulalongkorn-university\n",
            "     66 2215 0871 – 7 (Secretary office)\n",
            "faculty-of-political-science-chulalongkorn-university\n",
            "     66 2218 7250 – 3\n",
            "faculty-of-psychology-chulalongkorn-university\n",
            "     66 2218 1189\n",
            "faculty-of-science-chulalongkorn-university\n",
            "     66 2218 5000\n",
            "faculty-of-sports-science-chulalongkorn-university\n",
            "     66 2218 1032\n",
            "faculty-of-veterinary-science-chulalongkorn-university\n",
            "     66 2218 9771 – 3\n"
          ]
        }
      ],
      "source": [
        "# ---- TO DO 3 : Code Here ----\n",
        "url = 'https://comprogchula.github.io/'\n",
        "html = str(urq.urlopen(url).read().decode('utf-8'))\n",
        "\n",
        "op,ed,a = [],[],[]\n",
        "for i in range(len(html)):\n",
        "    if(html[i:i+2] == \"<a\"):op+=[i]\n",
        "    if(html[i:i+2] == \"a>\"):ed+=[i+2]\n",
        "\n",
        "for i in range(len(op)):a+=[html[op[i]:ed[i]]]\n",
        "\n",
        "uris = []\n",
        "for tag in a:\n",
        "    if(\"Faculty\" not in tag):continue\n",
        "    quote,uri=0,\"\"\n",
        "    for i in tag:\n",
        "        if(i == '\"'):quote+=1\n",
        "        elif(quote==1):uri+=i\n",
        "    uris+=[uri]\n",
        "\n",
        "for warp in uris:\n",
        "    print(warp[warp.find(\"faculty\"):warp.rfind(\".html\")])\n",
        "    html = str(urq.urlopen(warp).read().decode('utf-8'))\n",
        "    ok = False\n",
        "    for i in range(len(html)):\n",
        "        if(html[i:i+17] == \"content-contact-2\"):ok=True\n",
        "        \n",
        "        if(ok and html[i:i+13] == \"Tel:</strong>\"):\n",
        "            op,ed = i+13,i+23\n",
        "            while(html[op]!=\"+\"):op+=1\n",
        "            while(html[ed]!=\"<\"):ed+=1\n",
        "            \n",
        "            print(\"    \",html[op+1:ed])\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6qXu-BSkMhv"
      },
      "source": [
        "# TO DO 4: Crawl faculty of CP (1%)\n",
        "\n",
        "Current Faculty Members and Retired Faculty Members\n",
        "\n",
        "from https://www.cp.eng.chula.ac.th/en/about/faculty/\n",
        "\n",
        "*** Crawl only active members that have image ***\n",
        "\n",
        "**hint:** There are multiple strategies. To make it simple, we also accept a solution that list Dr. PITCHAYA as well. Another way is to check whether the image is the same filecmp.cmp https://docs.python.org/3/library/filecmp.html can do this. Or you can use if statements to exclude known exceptions.\n",
        "\n",
        "<img src=\"https://github.com/thcktw/Workshop2_Datascraping_Resource/raw/master/source/crawl_fac_member.png\" width=300>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_pattern(bik, smol, smol_ed):\n",
        "    a=[]\n",
        "    for i in range(len(bik)):\n",
        "        if(bik[i:i+len(smol)] == smol):\n",
        "            ed = i+len(smol)\n",
        "            while(html[ed:ed+len(smol_ed)] != smol_ed):ed+=1\n",
        "            a+=[(i,ed+1)]\n",
        "    return a\n",
        "\n",
        "def extract(data):\n",
        "    a={}\n",
        "    for i in range(len(data)):\n",
        "        if(data[i:i+14] == '<img src=\"http'):\n",
        "            op=i\n",
        "            while(data[op]!='\"'):op+=1\n",
        "            ed=op+10\n",
        "            while(data[ed]!='\"'):ed+=1\n",
        "            a['img_uri'] = data[op+1:ed].replace(\"amp;\", \"\")\n",
        "    \n",
        "    name_op,name_ed = find_pattern(data, \"<p>\", \"</a></p>\")[0]\n",
        "    name = data[name_op+3:name_ed]\n",
        "    \n",
        "    sttime = True\n",
        "    space_cnt = 0\n",
        "    cleaned = \"\"\n",
        "    for i in name:\n",
        "        if(space_cnt >=5 ): break\n",
        "        if(i == \" \" and sttime): continue\n",
        "        sttime=False\n",
        "        if(i == \" \"): space_cnt+=1\n",
        "        cleaned+=i\n",
        "\n",
        "    # print(cleaned)\n",
        "    a['name'] = cleaned\n",
        "\n",
        "    return a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DSh-mDUckMhw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Faculty Members\n",
            "\n",
            "PROF. DR. BOONSERM KIJSIRIKUL  \n",
            "PROF. DR. PRABHAS CHONGSTITVATANA  \n",
            "ASSOC. PROF. DR. ATHASIT SURARERKS \n",
            "ASSOC. PROF. DR. ATIWONG SUCHATO \n",
            "ASSOC. PROF. DR. CHOTIRAT RATANAMAHATANA \n",
            "ASSOC. PROF. DR. DUANGDAO  \n",
            "ASSOC. PROF. DR. KRERK PIROMSOPA \n",
            "ASSOC. PROF. DR. KULTIDA ROJVIBOONCHAI \n",
            "ASSOC. PROF. DR. NUTTAPONG CHENTANEZ \n",
            "ASSOC. PROF. DR. PEERAPON VATEEKUL \n",
            "ASSOC. PROF. DR. PROADPRAN PUNYABUKKANA \n",
            "ASSOC. PROF. DR. SETHA PAN-NGUM \n",
            "ASSOC. PROF. DR. TARATIP SUWANNASART \n",
            "ASSOC. PROF. DR. THANARAT CHALIDABHONGSE \n",
            "ASSOC. PROF. DR. TWITTIE SENIVONGSE \n",
            "ASSOC. PROF. DR. VISHNU KOTRAJARAS \n",
            "ASSOC. PROF. DR. WIWAT VATANAWOOD \n",
            "ASSOC. PROF. DR. YACHAI LIMPIYAKORN \n",
            "ASSOC. PROF. NAKORNTHIP PROMPOON  \n",
            "ASST. PROF. DR. ARTHIT THONGTAK \n",
            "ASST. PROF. DR. ATTAWITH SUDSANG \n",
            "ASST. PROF. DR. KUNWADEE  \n",
            "ASST. PROF. DR. NATAWUT NUPAIROJ \n",
            "ASST. PROF. DR. NATTEE NIPARNAN \n",
            "ASST. PROF. DR. PIZZANU KANONGCHAIYOS \n",
            "ASST. PROF. DR. SUKREE SINTHUPINYO \n",
            "ASST. PROF. DR. VEERA MUANGSIN \n",
            "ASST. PROF. CHATE PATANOTHAI  \n",
            "DR. EKAPOL  CHUANGSUWANICH  \n",
            "DR. JESSADA THUTKAWKORAPIN   \n",
            "DR. NUENGWONG TUAYCHAROEN   \n",
            "DR. PITTIPOL  KANTAVAT  \n",
            "DR. PUNNARAI  SIRICHAROEN  \n",
            "THONGCHAI ROJAKANGSADAN    \n",
            "\n",
            "Retired Faculty Members\n",
            "\n",
            "ASSOC. PROF. DR. PORNSIRI MUENCHAISRI \n",
            "Assc.Prof. Dr. SARTID VONGPRADHIP  \n",
            "ASSOC. PROF. DR. SOMCHAI PRASITJUTRAKUL \n",
            "Assc.Prof. Dr. WANCHAI RIVEPIBOON  \n",
            "Assc.Prof. MANDHANA PRAKANSAMUT   \n",
            "Asst.Prof. Dr. SUEBSKUL PHIPHOBMONGKOL  \n",
            "Asst.Prof. BOONCHAI SOWANWANICHAKUL   \n",
            "Asst.Prof. Korbkul Tejavanija   \n",
            "Asst.Prof. THANAWAN CHANTARATANAPIBUL   \n",
            "Dr. YUNYONG TENG-AMNUAY   \n"
          ]
        }
      ],
      "source": [
        "# ---- TO DO 4 : Code Here ----\n",
        "import filecmp\n",
        "\n",
        "\n",
        "url = \"https://www.cp.eng.chula.ac.th/en/about/faculty/\"\n",
        "html = str(urq.urlopen(url).read().decode('utf-8'))\n",
        "\n",
        "instructor = find_pattern(html, '<tr class=\"instructorRow\"', \"</tr>\")\n",
        "c=0;print(\"Current Faculty Members\\n\")\n",
        "for op,ed in instructor:    \n",
        "    data = html[op:ed].replace('\\n','')\n",
        "    info = extract(data)\n",
        "    #print(info, '\\n')\n",
        "    \n",
        "    if(\"Interest\" in info['name']): continue\n",
        "\n",
        "    # see if the picture in none\n",
        "\n",
        "    d = urq.urlopen(info['img_uri'])\n",
        "    path = './professor/check.jpg'\n",
        "    I = open(path, 'wb')\n",
        "    I.write(d.read())\n",
        "\n",
        "    comp = filecmp.cmp(path, './professor/none.jpg')\n",
        "    if(comp):continue\n",
        "\n",
        "    print(info['name'])\n",
        "    c+=1\n",
        "    if(c==34):print(\"\\nRetired Faculty Members\\n\")\n",
        "    if(c==44):break\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmL5uX5RWp2f"
      },
      "source": [
        "# To Do 5\n",
        "\n",
        "ทดลองดึงข้อมูลจาก dek-d.com ดูสิ :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6r8NQmAYkMhy"
      },
      "outputs": [],
      "source": [
        "dd_url = 'https://www.dek-d.com/home/writer/'\n",
        "nh_url = 'https://nhentai.net/api/galleries/search?sort=popular&query=uploaded:%3C1d'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAFkUJU0YCaF"
      },
      "source": [
        "ลองรันโค๊ดบรรทัดด้านล่างดู"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GVrU9jG0XjvF"
      },
      "outputs": [
        {
          "ename": "HTTPError",
          "evalue": "HTTP Error 403: Forbidden",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/catsunoki/2110101-com-prog/webscrape/00_web_scraping_with_str_functions_2021.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/catsunoki/2110101-com-prog/webscrape/00_web_scraping_with_str_functions_2021.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m html \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(urq\u001b[39m.\u001b[39;49murlopen(dd_url)\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n",
            "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 222\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
            "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:531\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[1;32m    530\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 531\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[1;32m    533\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:640\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[0;32m--> 640\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[1;32m    641\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[1;32m    643\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:569\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[1;32m    568\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[0;32m--> 569\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
            "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    501\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    503\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:649\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 649\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
          ]
        }
      ],
      "source": [
        "html = str(urq.urlopen(dd_url).read().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9G_ZbZsYMUh"
      },
      "source": [
        "จะพบว่าเกิด error ขึ้นเนื่องจากเว็บ dek-d มีการป้องกันไว้ \n",
        "\n",
        "หากเราต้อง scrape จะต้องส่ง user-agent เช่น Web-browser, Accept-Charset, Accept-Encoding เป็นต้น เพื่อหลอกเว็บไซต์ว่าเรากำลังใช้เว็บในการ request ข้อมูลเพจ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeVk4zsWZLZ0"
      },
      "outputs": [],
      "source": [
        "headers={'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'} \n",
        "\n",
        "\n",
        "dd_request = urq.Request(dd_url,None,headers) \n",
        "dd_html = str(urq.urlopen(dd_request).read().decode('utf-8'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNO0U9aYf0Id"
      },
      "source": [
        "ลองดึงข้อมูล title นิยายจากเว็บ https://www.dek-d.com/home/writer/ ดูสิ!!!\n",
        "\n",
        "\n",
        "#### ตัวอย่าง output \n",
        "\n",
        "<img src=\"https://github.com/Mixelon-tera/Workshop2_Datascraping_Resource/raw/master/source/dek_d_fiction.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQjDoNJKXESX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "เกิดอีกครั้งในยุค 80 ชาตินี้ไม่ใหญ่ไม่ได้\n",
            "เกิดอีกครั้งในยุค 80 ชาตินี้ไม่ใหญ่ไม่ได้\n",
            "เกิดอีกครั้งในยุค 80 ชาตินี้ไม่ใหญ่ไม่ได้\n",
            "鬼怪 นางมาร (ปิดตอนวันที่ 1 กันยายน)\n",
            "(อ่านฟรีทุกวัน) ทะลุมิติไปเป็นแพทย์หญิงชนบทตัวน้อยๆ : ความมั่งคั่งร่ำรวยมาถึงประตูของท่านแล้ว [นิยายแปล]\n",
            "หลี่อี้เฟย\n",
            "(อ่านฟรีทุกวัน วันละ 2 ตอน) เกิดใหม่ชาตินี้ ขอเป็นเศรษฐีนีในยุค 80 [นิยายแปล]\n",
            "(อ่านฟรีทุกวัน วันละ 2 ตอน) คู่มือเศรษฐีนีชาวนาฉบับสาวน้อยทะลุมิติ [นิยายแปล]\n",
            "ทะลุมิติมาเป็นแม่ลูกสองในยุค1978\n",
            "จ้าวลู่ชิง คหบดีหญิงแห่งต้าถัง\n",
            "ใครส่งข้ามาป่วน\n",
            "พฤกษาสวรรค์หวนคืน\n",
            "(อ่านฟรีทุกวัน) ทะลุมิติไปเป็นภรรยาชาวสวนของท่านบัณฑิต [นิยายแปล]\n",
            "นางร้ายทะลุมิติไปเป็นคุณแม่ลูกสี่ยุค 70\n",
            "สาวใช้อันดับหนึ่ง\n",
            "ผักวิญญาณพวกนี้ฉันเป็นคนปลูก\n",
            "(อ่านฟรีทุกวัน วันละ 2 ตอน) ภรรยานายพรานตัวน้อยกับระบบร้านค้ามือสอง [นิยายแปล]\n",
            "[อ่านฟรีทุกวัน] ทะลุมิติไปเป็นสาวนาผู้ร่ำรวย [ 农女致富记 ]\n",
            "หนูน้อยสกุลถัง\n",
            "หมอหญิงทะลุมิติกับตำราวิเศษ\n",
            "(อ่านฟรีทุกวัน วันละ 2 ตอน) ทะลุมิติไปทำฟาร์มกับหมอหญิงตัวน้อย [นิยายแปล]\n",
            "ภารกิจพิชิตใจสามีในยุคปลาย70 (รีบอ่านก่อนติดเหรียญวันที่ 1 กันยายนนี้นะคะ)\n"
          ]
        }
      ],
      "source": [
        "# ---- OPTIONAL : Code Here ----\n",
        "\n",
        "headers={'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'} \n",
        "\n",
        "\n",
        "dd_request = urq.Request(dd_url,None,headers) \n",
        "dd_html = str(urq.urlopen(dd_request).read().decode('utf-8'))\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(dd_html, \"html.parser\")\n",
        "\n",
        "a = soup.find_all(\"a\", class_=\"card__title\")\n",
        "for i in a:\n",
        "    print(i.text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "00_web_scraping_with_str_functions_2021",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
